Overview
This guide describes how to train models using Metaflow, an open-source ML framework that we’ve integrated with Adroit. Compared to the legacy Adroit training process, Metaflow has the following benefits:

Training workflows are specified as DAGs (rather than linear sequences) of steps, allowing for more flexibility and parallelization during training.

The entire training process is captured in a single entrypoint, removing the need for modelers to remember and run multiple commands. This also improves training reproducibility and will enable us to easily set up automated retraining.

There is less obfuscation of data locations compared to legacy Adroit training. This addresses one of the most common pain points with legacy Adroit training around mapping data paths.

All runs are tracked in a centralized DB and can be accessed from a web UI, increasing shareability.

Installation
Metaflow is already included in the (legacy) adroit conda environment. You may need to run make build_env to install the latest version of the environment.

Metaflow also works with Adroit’s custom conda environments. These environments allow you to run code that requires a different set of dependencies than what’s included in legacy Adroit. Refer to the Custom Conda Environments User Guide for details on using these environments.

Configuration
In addition to installing the Python dependencies, you’ll also need to set up access to remote resources for the full Metaflow experience. Metaflow uses S3 as a datastore and also talks to API and UI services that we have running in Kubernetes.

There are three scripts in the ./bootstrap directory to help set up Metaflow:

Run ./bootstrap/configure_metaflow.sh to create a Metaflow config file that will point it to the correct resources. This only needs to be done once, since all Metaflow installations will automatically pick up and read config from the ~/.metaflowconfig directory if it exists.

Note that when it asks you to create a Databricks token – this is for the interactive workspace: https://nextdoor-interactive.cloud.databricks.com (all our MLflow stuff lives here, not in the prod workspace). Also, if you’ve never run MLflow experiments before, you will need to create a personal directory for your experiments (see the note in the MLflow section below).

For these next two you need to be logged in to the AWS Data account (where we run Metaflow remote resources). Use aws_data_login -–reup to do this.

Run source ./bootstrap/activate_metaflow.sh to set environment variables necessary for Metaflow to work. This needs to be run in each terminal session you plan to run Metaflow commands in.

Run bash ./bootstrap/metaflow_port_forwarding.sh to set up access to Kubernetes resources. This needs to be kept running in a separate terminal while you use Metaflow.

Authoring Flows
The core concept of Metaflow is a flow, which is a DAG of steps defined via a Python class. To create a flow, create a class that inherits from metaflow.FlowSpec. Steps are defined as instance methods (using the @step) decorator and transitions between steps are defined by calling self.next() at the end of each step. Data persisted on self will be saved as Metaflow artifacts and will be accessible across steps (even remotely).

Here’s a high level example of a flow:

class MyFlow(FlowSpec):
   @step
   def start(self):
       # All flows must have a start step
       self.next(self.run_query)

   @step
   def run_query(self):
       # Run a query to get training data
       self.train_data, self.test_data = get_data()
       ...
       self.next(self.train_model)

   @step
   def train_model(self):
       # Train and evaluate the model
       # Models and metrics should be pushed to MLflow
       model = train_model(self.train_data)
       ...
       self.next(self.end)

   @step
   def end(self):
       # All flows must have an end step
       print("Done!")
For more details on writing flows, refer to the Metaflow docs here.

Data access patterns
In contrast to legacy Adroit, there is no concept of DataManagers vs Trainers in Metaflow. Instead, you are free to access data directly from any step. You do not need to map data paths but instead can access data directly from the Data Lake or S3, and can save data as instance variables in order to pass it between steps.

Some common patterns include:

Having a step that runs a query to pull data from the Data Lake into memory, and then accessing that data in a subsequent training step via self.

Running a query that directly puts results into S3, and then accessing data from S3 using the Metaflow S3 client.

Metaflow steps (including remote ones) have access to the dev-scratch.datalake.nextdoor.com and adroit-training buckets. For more details on data access from Metaflow, refer to the docs here.

Note: we run Metaflow in the Data AWS account, not the Eng account. This allows access to the dev-scratch bucket but not the adroit-training bucket in the Eng account that legacy training uses. DVC is also currently not supported in the Data account (reach out to @coreml if this is a need and we can get it added).

External Dependencies
When running locally, Metaflow uses the same Python environment as the command it’s called from. For example, if you have the legacy adroit conda environment activated, then Metaflow will be able to access the packages in that environment. For more details, refer to the Metaflow docs here.

If you need to use custom packages such as PyTorch in a local Metaflow step, you can use a custom Adroit conda environment.

Metaflow also provides a @conda decorator that enables specifying custom dependencies, but it’s a little awkward to use since it requires explicitly listing out all the required packages. We recommend using pre-baked Adroit conda envs instead.

For remote execution, the available packages are determined by the Docker image used to run the step. When using custom packages, this should be set to a custom conda env image that has the necessary dependencies for the step.

Remote Execution (in_sagemaker)
Metaflow supports executing steps remotely using AWS Batch, but based on feedback from #cloudeng we decided not to provision additional AWS resources for that, and instead use Metaflow’s Kubernetes support for remote execution when it’s ready. In the meantime, we have added support for running steps remotely using our existing Sagemaker infrastructure.

To specify that a step should be run in Sagemaker, add the @in_sagemaker decorator to the step. For example:

@in_sagemaker
@step
def myStep(self):
   ...
Available parameters include:

image – ECR image URL to use for the job. This can point to the legacy Adroit training image or one of the new custom conda env images.
instance_type – AWS instance type to use for the job (defaults to ml.m5.large).
volume_size – disk space in Gb to allocate (defaults to 30 Gb)
max_run – timeout in seconds for the job (defaults to 1 day).
wait – Whether or not to wait for the Sagemaker job to complete before proceeding with Flow execution. By default, this is true.
To run a step that has the in_sagemaker decorator applied locally, you can use the MF_IGNORE_SAGEMAKER env var (e.g. MF_IGNORE_SAGEMAKER=true python flow.py run). This is useful for debugging step code locally without needing to manually comment out the decorator.

Note: one limitation of Sagemaker execution is that data artifacts (i.e. instance vars) created/updated during a remote step will not be accessible to subsequent steps (data artifacts created before the step are accessible). Use MLflow to get artifacts such as models and metrics out of Sagemaker.

Note: when requesting a specific volume size for your Sagemaker instance it gets mounted under /opt/ml and not /opt/adroit. This means that attempting to load large files outside of /opt/ml will lead to disk space errors. To avoid this, set /opt/ml/input as the directory Metaflow uses to download files (example here).

Remote Execution Sagemaker Logs
Functions decorated with in_sagemaker will be executed remotely in.. Sagemaker. Any debug print from these functions will appear in Sagemaker logs. You may follow any online documentation to find Sagemaker logs.

In short:

Log via Okta into the AWS-Data account.
Click on Sagemaker -> Training -> search for your job (I use the runtime and name to find my jobs).
From there on in the job page you can find a Logs button.
Example photos of this process for a "Failed" job run at 14:30 PST (or 22:30 UTC):

image image image

MLflow Integration
MLflow is another important aspect of our new approach to model training. It serves as our experiment tracking server + model registry. Metaflow runs should log metrics and model artifacts to MLflow so that they can be tracked and shared in one place. This also serves as the bridge between Metaflow runs and Adroit models -- model training runs in Metaflow should produce MLflow model artifacts that can then be served in Adroit (for more details on serving MLflow models in production refer to the Publishing section below).

MLflow access is set up locally as part of the ./bootstrap/configure_metaflow.sh and ./bootstrap/activate_metaflow.sh scripts. For remote runs, Sagemaker has already been set up so that it can write to MLflow.

Note: you need to create a personal MLflow experiment directory (e.g. /Shared/mlflow/experiments/{user}@nextdoor.com) via the Databricks UI before running your first experiment. We plan to add code to automatically create this directory but haven’t had time to get to it given other priorities.

When running a flow, make sure the USER on your local machine is the same as the one in MLFlow. If it's not, you can override it at runtimevia command line by using the env. variables METAFLOW_USER or USER.

Logging to MLflow
We provide the NextdoorMLFlowRunPublisher class to make logging models and metrics to MLflow easier. Refer to the in-code documentation for each of the methods for more details on logging specific types of artifacts.

MLflow model format
Adroit can serve any python_function MLflow model. The python_function flavor in MLflow is a generic model interface for Python models and enables us to use various libraries such as Scikit-learn or PyTorch behind the scenes.

For most purposes, we recommend creating a model class that inherits from mlflow.pyfunc.PythonModel. This allows you to have full control over your model's behavior at prediction time, by implementing the predict method as necessary. There is a pre-built MLflowHandler in Adroit that can be used, so if your model implements all the necessary inference logic in predict there's no need to write your own handler.

For example, here's a model that contains both a Sklearn pipeline and a PyTorch model:

class MyModel(mlflow.pyfunc.PythonModel):
    def __init__(self, sklearn_pipeline=None):
        """Overriden constructor to enable setting a sklearn pipeline.

        Pickle-able objects can be saved directly on the model class since the entire
        class gets pickled when saving the MLflow model.
        """
        self.sklearn_pipeline = sklearn_pipeline

    def load_context(self, context):
        """Called by MLflow when initializing your model from disk."""
        self.pytorch = torch.load(context.artifacts["pytorch_model"])

    def predict(self, context, model_input):
        """Implement your custom predict logic here.

        model_input can be a tensor or DataFrame depending on what the upstream handler
        passes to the model.
        """
        self.transformed = self.sklearn_pipeline.transform(model_input)
        return self.pytorch_model(self.transformed)
As you may notice, we don't include any training logic in this model definition. Instead, it's a simple wrapper around already-trained artifacts. The model would be logged to MLflow after training completes, by doing something like this:

@step
def train(self):
    # Create sklearn pipeline for preprocessing
    sklearn_pipeline = ...

    # Create and fit PyTorch model
    pytorch_model = ...
    self._fit_pytorch_model(sklearn_pipeline, self.data)

    # Save PyTorch model to temporary local file
    tmpdir = tempfile.TemporaryDirectory()
    model_path = pathlib.Path(tmpdir.name) / "model.pt"
    torch.save(self.pytorch_model, model_path)

    # We'll pass in the local path as an artifact
    # This will allow us to access the saved PyTorch model under
    # context.artifacts["pytorch_model"]
    artifacts = {"pytorch_model": model_path}

    # The Sklearn pipeline will get pickled directly
    mlflow_model = MyModel(sklearn_pipeline=sklearn_pipeline)

    self.mlflow_publisher.log_model(
        model=mlflow_model,
        artifacts=artifacts,
        X_test=self.sample_input,
        y_test=self.sample_output,
        code_path=["data_prep.py"] # Add any code dependencies here
    )
Some other things to be aware of:

Because MLflow pickles the model class, you need to make sure all code dependencies are included with the model. To do this, use the code_path argument in the NextdoorMLFlowRunPublisher.log_model() function.

The X_test and Y_test arguments in log_model will be used to infer the input and output signature of the model. MLflow performs type checking at inference time and will throw an error for type mismatches, so make sure the schemas of these match what you expect for inference. Alternatively, use log_signature=False to bypass signature validations.

Because the MLflow model is produced as an output from training, it can be cumbersome to have to rerun training to make small changes to the model class. For that reason, it's recommended to first validate that your model pipeline works end to end on a small test dataset before running the full training flow.

These pages from the MLflow docs are also useful:

https://www.mlflow.org/docs/latest/models.html#custom-python-models
Running Flows
Before executing a flow, make sure that you’ve followed the instructions in the Installation and Configuration sections above.

The entrypoint to execute flows is your flow file itself. For example, if you’ve defined your flow in my_flow.py, then you’d execute it by running python my_flow.py <command>. Common commands include:

python my_flow.py run – run the flow from the start.
python my_flow.py resume – resume the flow from the last failed step.
python my_flow.py resume <step> – resume the flow from a specific step.
Refer to the Metaflow docs here for more details. Note that flows should be located in the current working directory when executing.

Accessing the Web UI
If you're running ./bootstrap/metaflow_port_forwarding.sh, you’ll be able to access the UI at http://localhost:8083. We also have the UI exposed over the internet at https://metaflow.analytics.nextdoor.com but live updates via Websocket are currently not supported yet.

Publishing Models
Note that unlike legacy Adroit training, Metaflow runs do not need to have a 1:1 correspondence with published Adroit models. Instead, a Metaflow run can push as many model artifacts to MLflow as desired (this is useful for hyperparameter tuning, for example). Then, each model can be inspected along with its corresponding metrics, and an Adroit model only needs to be published for the best MLflow artifact when ready.

To publish an Adroit model from a MLflow artifact, use the following steps:

In your project directory, write a handler (or use an existing handler, such as the MlflowHandler) and Adroit config file (config.yaml). Your config will only require a serve section since training happens in Metaflow.

model_name: &model_name example_metaflow  # model_name should match directory

serve:
 handler:
   class_path: adroit.serving.mlflow_handler:MlflowHandler  # Default Handler, can be overridden
   kwargs:
     model_name: *model_name
     log_features_percent: 0.1  # DataDog feature drift monitoring as a percentage of requests
Create a new flavor for your model in flavors.yaml (if your model is based on another model, you can copy paste that flavor). Your new flavor should point to the config you wrote above and reference the same conda env you used for training.

Set the version in your new flavor to be the MLFLow run id for the artifact you wish to deploy

Run AWS_PROFILE=eng AWS_DEFAULT_REGION=us-east-1 python publish_mlflow_model_flow.py run --flavor="<your flavor here>"

Note: running the above script requires AWS Engineering account credentials -- use aws_eng_login and use a fresh terminal session without Metaflow activated.

Copy the version outputed by the previous step to your flavor in flavors.yaml

Republishing
You need to republish (and update your model flavor's version in flavors.yaml) any time you change the source code that is necessary for inference, namely code in the projects/ ditectory. Republishing will update the code used for production model inferences. Since the model's source code is published together with the trained model's artifacts, you need to republish for any source code changes to have any effect in a deployed flavor.

aws_sso_login
train_model.py -v republish --model_name {PUBLISHED_MODEL_NAME} --version {PUBLISHED_MODEL_VERSION} --config_path {PATH/TO/NEW/SRC/CONFIG}
To guarantee a smooth transition to a new republished model version, you should:

Create a new flavor in flavors.yaml
Deploy the flavor and verify it works
Update the adroit_model_versions sitevar to point to the new flavor
Wait for model traffic to roll over
Delete the old flavor from flavors.yaml
Useful Links
Example Metaflow code to train a simple model with various sets of hyperparameters in parallel: https://github.com/Nextdoor/adroit/blob/main/projects/example_metaflow/flow.py

PR converting an existing Adroit model to use Metaflow: https://github.com/Nextdoor/adroit/pull/997

FAQ - Common errors
ValueError: Enum ErrorCode has no value defined for name '403' Resolved in this Slack thread. The issue arises when Metaflow cannot read the ~/.databrickscfg file. It can be temporarily fixed by using the following instead:
export DATABRICKS_TOKEN=...
export DATABRICKS_HOST=https://nextdoor-interactive.cloud.databricks.com/